{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import invgamma\n",
    "from geopy.distance import geodesic\n",
    "from dms_variants.ispline import Isplines, Isplines_total\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pymc as pm\n",
    "import sys\n",
    "\n",
    "# Add the module path to sys.path\n",
    "sys.path.append('../../')\n",
    "\n",
    "# Import the model_1_pymc function\n",
    "from models import model_1_pymc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of zeros: 0.0\n",
      "Proportion of ones: 0.08947368421052632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_357066/501244899.py:91: RuntimeWarning: invalid value encountered in log\n",
      "  np.where(lm_mod.coef_ > 0, np.log(lm_mod.coef_), -10),  # Log coefficients greater than 0, and set those < 0 to -10\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------\n",
    "# load in and parse data\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "dat_all = pd.read_csv(\"../../data/sa_family_data.csv\").sample(n=20,random_state=1)\n",
    "\n",
    "# Parse data into location, environmental variables, and species cover/presence\n",
    "location_mat = dat_all[['latitude', 'longitude']].values\n",
    "env_var_names = ['gmap', 'RFL_CONC', 'Elevation30m', 'HeatLoadIndex30m', 'tmean13c', 'SoilConductivitymSm', 'SoilTotalNPercent']\n",
    "envr_use = dat_all[['gmap', 'RFL_CONC', 'Elevation30m', 'HeatLoadIndex30m', 'tmean13c', 'SoilConductivitymSm', 'SoilTotalNPercent']].values\n",
    "species_mat = dat_all.iloc[:, 12:].values\n",
    "\n",
    "# Get the number of sites\n",
    "ns = location_mat.shape[0]\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "# Calculate Bray-Curtis dissimilarity -- see proportion of 0's and 1's\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "# Define dissimilarity metric\n",
    "diss_met = 'braycurtis'\n",
    "\n",
    "# Create pair-wise response matrix. pdist outputs a 1D matrix\n",
    "Z = pdist(species_mat, diss_met)\n",
    "\n",
    "# Find indices for observations with dissimilarity of exactly 1\n",
    "Z_is_one = np.where(Z == 1)[0]\n",
    "Z_is_not_one = np.where(Z != 1)[0]\n",
    "\n",
    "# Get counts\n",
    "n1 = len(Z_is_one)\n",
    "N = len(Z)\n",
    "\n",
    "# Print the proportion of zeros and ones in the dissimilarity matrix\n",
    "print(f\"Proportion of zeros: {np.mean(Z == 0)}\")\n",
    "print(f\"Proportion of ones: {np.mean(Z == 1)}\")\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "# Define covariates that will be warped by I-spline function AND coefficients\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "# Calculate pairwise geographical distance in km using geodesic with WGS84 in vector form (upper triangle of matrix)\n",
    "vec_distance = pdist(location_mat, lambda lat, lon: geodesic(lat, lon).kilometers)\n",
    "\n",
    "# Define a (sub)set of environmental variables to be used as covariates\n",
    "X = envr_use[:, [0, 1, 2, 3, 4, 5, 6]]\n",
    "\n",
    "# How many knots do you want? What is the degree of the spline?\n",
    "# Remember that in the specification, of the iSpline that the degree is\n",
    "# one higher that what you say. Integration of m-spline adds one degree.\n",
    "# Define the degree and number of knots for the I-spline basis\n",
    "deg = 3\n",
    "knots = 2\n",
    "order = deg + 1\n",
    "df = deg * knots\n",
    "\n",
    "# Create ISpline bases, with different range (i.e. mesh) for each variable. Note NO extrapolation with this method, only interpolation.\n",
    "I_spline_bases = np.column_stack([Isplines(order, [X[:,i].min(), X[:,i].min() + (X[:,i].max() - X[:,i].min())/3, X[:,i].min() + (X[:,i].max() - X[:,i].min())*2/3, X[:,i].max()], X[:,i]).I(j) for i in range(X.shape[1]) for j in range(1,df)])\n",
    "\n",
    "# Pairwise differences of each basis function in a vector. Shape ns**2 / 2 x p * df\n",
    "I_spline_bases_diffs = np.array([pdist(I_spline_bases[:, i].reshape(-1, 1), metric='euclidean') for i in range(I_spline_bases.shape[1])]).T\n",
    "\n",
    "# Create spline for the geodesic distances\n",
    "dist_mesh = [vec_distance.min(), vec_distance.min() + (vec_distance.max() - vec_distance.min())/3, vec_distance.min() + (vec_distance.max() - vec_distance.min())*2/3, vec_distance.max()]\n",
    "dist_splines = np.column_stack([Isplines(order, dist_mesh, vec_distance).I(i) for i in range(1, df)])\n",
    "\n",
    "# Combine the I-spline bases and the geographical distances\n",
    "X_GDM = np.column_stack([I_spline_bases_diffs, dist_splines])\n",
    "\n",
    "# Name columns\n",
    "column_names = [f\"{var}_I{j}\" for var in env_var_names for j in range(1, df)] + [f\"Dist_I{j}\" for j in range(1, df)]\n",
    "X_GDM_df = pd.DataFrame(X_GDM, columns=column_names)\n",
    "p = X_GDM.shape[1]\n",
    "\n",
    "# Get row and column indices for each dissimilarity \n",
    "row_ind, col_ind = np.triu_indices(ns, k=1)\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Get initial values to speed up spGDMM fitting\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "# Fit linear model\n",
    "lm_mod = LinearRegression(fit_intercept=True).fit(X_GDM, np.log(Z))\n",
    "\n",
    "# Define objective function\n",
    "objective = lambda params: np.sum((np.log(Z) - params[0] - X_GDM @ np.exp(params[1:(p+1)]))**2)\n",
    "\n",
    "# Set up initial parameters, taking logs of positive and setting negative coefficients to -10\n",
    "initial_params = np.concatenate([\n",
    "    [0.3],  # Intercept, why chosen to be this?\n",
    "    np.where(lm_mod.coef_ > 0, np.log(lm_mod.coef_), -10),  # Log coefficients greater than 0, and set those < 0 to -10\n",
    "    #np.random.randn(ns)  # Random values for each site\n",
    "])\n",
    "\n",
    "optimized_params = minimize(objective, initial_params, method='BFGS').x\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Fix spatial range parameter (rho = 1 / phi) heuristically (can also estimate using the data, or even deep GP). \n",
    "# Setting up spatial correlation structure.\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "rho_fix = np.max(vec_distance) / 10\n",
    "R_spat_mat = squareform(np.exp(- vec_distance / rho_fix))\n",
    "#chol_R = np.linalg.cholesky(R_spat_mat).T\n",
    "R_inv = np.linalg.inv(R_spat_mat)\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Define design matrix for a polynomial log-variance\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "# NOTE these features are not orthogonal as they were in the R implementation\n",
    "X_sigma = PolynomialFeatures(degree=3, include_bias=True).fit_transform(vec_distance.reshape(-1, 1))\n",
    "p_sigma = X_sigma.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_V' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m sigma2 \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mInverseGamma(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigma2\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     45\u001b[0m mu \u001b[38;5;241m=\u001b[39m beta_0 \u001b[38;5;241m+\u001b[39m linpred\n\u001b[0;32m---> 46\u001b[0m log_V_obs \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mNormal(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_V_obs\u001b[39m\u001b[38;5;124m'\u001b[39m, mu\u001b[38;5;241m=\u001b[39mmu, sigma\u001b[38;5;241m=\u001b[39mpm\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39msqrt(sigma2), observed\u001b[38;5;241m=\u001b[39m\u001b[43mlog_V\u001b[49m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Sample from the posterior with progress bar enabled\u001b[39;00m\n\u001b[1;32m     49\u001b[0m trace \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m1000\u001b[39m, return_inferencedata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, progressbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_V' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Source nimble models -- Models 1-9 match those in paper\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "# Create constants for the model\n",
    "constants = {\n",
    "    'n': N,\n",
    "    'p': p,\n",
    "    'x': X_GDM,\n",
    "    'n_loc': ns,\n",
    "    'p_sigma': p_sigma,\n",
    "    'X_sigma': X_sigma,\n",
    "    'R_inv': R_inv,\n",
    "    'zeros': np.zeros(ns),\n",
    "    'row_ind': row_ind,\n",
    "    'col_ind': col_ind\n",
    "}\n",
    "\n",
    "# Create data for the model\n",
    "data = {\n",
    "    'log_V': np.where(Z == 1, np.nan, np.log(Z)),\n",
    "    'censored': (Z == 1).astype(int),\n",
    "    'c': np.zeros(constants['n'])\n",
    "}\n",
    "\n",
    "# Create initial values for the model\n",
    "inits = {\n",
    "    'beta_0': optimized_params[0],\n",
    "    'log_beta': optimized_params[1:(p+1)],\n",
    "    'sig2_psi': 1,\n",
    "    'beta_sigma': np.array([-5, -20, 12, 2]),\n",
    "    'psi': optimized_params[(p+1):]\n",
    "}\n",
    "\n",
    "with pm.Model() as model:\n",
    "        # Define the priors\n",
    "        beta_0 = pm.Normal('beta_0', mu=0, sigma=10)\n",
    "        beta = pm.Lognormal('beta', mu=0, sigma=10, shape=p)\n",
    "\n",
    "        # Calculate the linear predictor\n",
    "        linpred = pm.math.dot(X_GDM[:,1:p+1], beta)\n",
    "        \n",
    "        # Define the likelihood\n",
    "        sigma2 = pm.InverseGamma('sigma2', alpha=1, beta=1)\n",
    "        mu = beta_0 + linpred\n",
    "        log_V_obs = pm.Normal('log_V_obs', mu=mu, sigma=pm.math.sqrt(sigma2), observed=log_V)\n",
    "        \n",
    "        # Sample from the posterior with progress bar enabled\n",
    "        trace = pm.sample(1000, return_inferencedata=True, progressbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.0.3 (20230418.1244)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"427pt\" height=\"138pt\"\n",
       " viewBox=\"0.00 0.00 427.50 137.95\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 133.95)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-133.95 423.5,-133.95 423.5,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster40</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M271.5,-8C271.5,-8 399.5,-8 399.5,-8 405.5,-8 411.5,-14 411.5,-20 411.5,-20 411.5,-109.95 411.5,-109.95 411.5,-115.95 405.5,-121.95 399.5,-121.95 399.5,-121.95 271.5,-121.95 271.5,-121.95 265.5,-121.95 259.5,-115.95 259.5,-109.95 259.5,-109.95 259.5,-20 259.5,-20 259.5,-14 265.5,-8 271.5,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"394\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">40</text>\n",
       "</g>\n",
       "<!-- beta_0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>beta_0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"49.5\" cy=\"-76.48\" rx=\"49.49\" ry=\"37.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"49.5\" y=\"-87.78\" font-family=\"Times,serif\" font-size=\"14.00\">beta_0</text>\n",
       "<text text-anchor=\"middle\" x=\"49.5\" y=\"-72.78\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"49.5\" y=\"-57.78\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- sigma2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>sigma2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"183.5\" cy=\"-76.48\" rx=\"66.44\" ry=\"37.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-87.78\" font-family=\"Times,serif\" font-size=\"14.00\">sigma2</text>\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-72.78\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-57.78\" font-family=\"Times,serif\" font-size=\"14.00\">InvGamma</text>\n",
       "</g>\n",
       "<!-- beta -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>beta</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"335.5\" cy=\"-76.48\" rx=\"67.76\" ry=\"37.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"335.5\" y=\"-87.78\" font-family=\"Times,serif\" font-size=\"14.00\">beta</text>\n",
       "<text text-anchor=\"middle\" x=\"335.5\" y=\"-72.78\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"335.5\" y=\"-57.78\" font-family=\"Times,serif\" font-size=\"14.00\">LogNormal</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f6a065feba0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apply', 'BatchedDiag', 'LogDet', 'Op', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'abs', 'and_', 'arccos', 'arccosh', 'arcsin', 'arcsinh', 'arctan', 'arctanh', 'batched_diag', 'block_diagonal', 'broadcast_to', 'cartesian', 'ceil', 'clip', 'concatenate', 'constant', 'cos', 'cosh', 'cumprod', 'cumsum', 'dot', 'eq', 'erf', 'erfc', 'erfcinv', 'erfinv', 'exp', 'expand_packed_triangular', 'flat_outer', 'flatten', 'flatten_list', 'floatX', 'floor', 'full', 'full_like', 'ge', 'gt', 'invlogit', 'invprobit', 'kron_diag', 'kron_dot', 'kron_matrix_op', 'kron_solve_lower', 'kron_solve_upper', 'kronecker', 'le', 'log', 'log1mexp', 'log1mexp_numpy', 'log1pexp', 'log_softmax', 'logaddexp', 'logbern', 'logdet', 'logdiffexp', 'logdiffexp_numpy', 'logit', 'logsumexp', 'lt', 'matmul', 'matrix_inverse', 'max', 'maximum', 'mean', 'min', 'minimum', 'neq', 'np', 'ones', 'ones_like', 'or_', 'partial', 'probit', 'prod', 'pt', 'pytensor', 'reduce', 'round', 'sgn', 'sigmoid', 'sin', 'sinh', 'softmax', 'solve_triangular', 'sqr', 'sqrt', 'stack', 'sum', 'switch', 'sys', 'tan', 'tanh', 'warnings', 'where', 'zeros', 'zeros_like']\n",
      "dot.0\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "\n",
    "# Check if pm.math is available\n",
    "print(dir(pm.math))\n",
    "\n",
    "# Example usage of pm.math.dot\n",
    "import numpy as np\n",
    "\n",
    "X = np.random.randn(100, 5)\n",
    "beta = np.random.randn(5)\n",
    "\n",
    "linpred = pm.math.dot(X, beta)\n",
    "print(linpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.16.2\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "print(pm.__version__)\n",
    "from pymc import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spGDMM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
